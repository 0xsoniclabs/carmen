import sys
from itertools import accumulate

import pandas as pd

MAX_SPECIALIZATIONS = 5

DEBUG = False
PRINT_TABLE = False

# The default CSV to load. This can be overridden by a command-line argument.
# Data is generated by ../rust/src/bin/node_stats.rs
CSV_PATH = "../rust/carmen_stats_node_counts_by_kind.csv"

# NOTE: These sizes are based on the current implementation of the trie nodes in Carmen and needs to be manually updated if the implementation changes.

# --- Node size constants ---
# The size of the commitment stored in both inner and leaf nodes
COMMITMENT_SIZE = 32

# --- Inner node constants ---
# The size of a node id stored in inner nodes
ID_SIZE = 6
# The size of the index for a node id stored in sparse inner nodes
ID_INDEX_SIZE = 1
# The number of children of a full inner node
INNER_NODE_CHILDREN = 256
# The size of a full inner node
FULL_INNER_NODE_SIZE = COMMITMENT_SIZE + INNER_NODE_CHILDREN * ID_SIZE

# --- Leaf node constants ---
# The size of a value stored in leaf nodes
VALUE_SIZE = 32
# The size of the index for a value stored in sparse leaf nodes
VALUE_INDEX_SIZE = 1
# The size of the stem in leaf nodes
STEM_SIZE = 31
# The number of children of a full leaf node
LEAF_NODE_CHILDREN = 256
# The number of used bits in a leaf node
USED_BITS = 256 / 8
# The size of a full leaf node
FULL_LEAF_NODE_SIZE = (
    COMMITMENT_SIZE + LEAF_NODE_CHILDREN * VALUE_SIZE + STEM_SIZE + USED_BITS
)

INT_MAX = sys.maxsize


def sparse_leaf_node_size(num_children: int) -> int:
    """Return the size of a sparse leaf node with the given number of children."""
    return (
        COMMITMENT_SIZE
        + num_children * (VALUE_SIZE + VALUE_INDEX_SIZE)
        + STEM_SIZE
        + USED_BITS
    )


def get_leaf_node_sizes() -> list[int]:
    """Return a list of leaf node sizes for all possible numbers of children."""
    leaf_node_sizes = [sparse_leaf_node_size(n) for n in range(256)]
    leaf_node_sizes.append(FULL_LEAF_NODE_SIZE)
    return leaf_node_sizes


def sparse_inner_node_size(num_children: int) -> int:
    """Return the size of a sparse inner node with the given number of children."""
    return COMMITMENT_SIZE + num_children * (ID_SIZE + ID_INDEX_SIZE)


def get_inner_node_sizes() -> list[int]:
    """Return a list of inner node sizes for all possible numbers of children."""
    inner_node_sizes = [sparse_inner_node_size(n) for n in range(INNER_NODE_CHILDREN)]
    inner_node_sizes.append(FULL_INNER_NODE_SIZE)
    return inner_node_sizes


def find_best_specializations(counts, sizes, num_specializations):
    """Find the best specializations for a given list of node counts and sizes, using dynamic programming.
    Args:
        counts (list[int]): List of counts for nodes with 0 to 256 children.
        sizes (list[int]): List of sizes of nodes with 0 to 256 children.
        specializations (int): Number of specializations to consider.
    Returns:
        best_specializations (list[int]): List of the number of children for the best specializations.
        min_cost (int): The minimum storage cost achieved with the best specializations.
        cost_table (list): The dynamic programming table of costs for each range and number of specializations.
        witness_table (list): The dynamic programming table of witness indices for each range and number of specializations.
    """

    count_prefix_sum = list(accumulate(counts))

    # cost_table[start][end][num_specializations]
    cost_table = [
        [[INT_MAX for _ in range(num_specializations)] for _ in range(len(counts))]
        for _ in range(len(counts))
    ]
    # witness_table[start][end][num_specializations]
    witness_table = [
        [[[] for _ in range(num_specializations)] for _ in range(len(counts))]
        for _ in range(len(counts))
    ]
    for end in range(len(counts)):
        for start in range(end + 1):
            if start == 0:
                cost = sizes[end] * count_prefix_sum[end]
                cost_table[start][end][0] = cost
                witness_table[start][end][0] = [end]
            else:
                for level in range(start):
                    for num_spec in range(num_specializations - 1):
                        cost = cost_table[level][start - 1][num_spec]
                        witness = witness_table[level][start - 1][num_spec]
                        if cost == INT_MAX:
                            continue
                        cost += sizes[end] * (count_prefix_sum[end] - count_prefix_sum[start - 1])
                        if cost < cost_table[start][end][num_spec + 1]:
                            cost_table[start][end][num_spec + 1] = cost
                            witness_table[start][end][num_spec + 1] = witness + [end]

    min_cost, best_specializations = min(
        (
            (
                cost_table[start][len(counts) - 1][num_spec],
                witness_table[start][len(counts) - 1][num_spec],
            )
            for start in range(len(counts))
            for num_spec in range(num_specializations)
        ),
        key=lambda x: x[0],
        default=(INT_MAX, []),
    )
    return best_specializations, min_cost, cost_table, witness_table


def print_best_specializations(node_name, counts, sizes):
    """Print the best specializations for a given node type, counts, and sizes."""

    print(f"--- Node type: {node_name} ---")
    for num_specializations in range(1, MAX_SPECIALIZATIONS + 1):
        best_specializations, min_cost, cost_table, witness_table = find_best_specializations(
            counts, sizes, num_specializations
        )

        print(f"Num Specializations: {num_specializations}")
        print(f"Min cost: {min_cost}")
        print(f"Specializations: {best_specializations}\n")
        if PRINT_TABLE:
            table = []
            for start in range(len(cost_table)):
                row = []
                for end in range(len(cost_table[start])):
                    if start > end:
                        row.append("")
                        continue
                    entries = []
                    for spec in range(num_specializations):
                        cost = cost_table[start][end][spec]
                        witness = witness_table[start][end][spec]
                        cost_str = str(cost) if cost != INT_MAX else "INF"
                        entry = f"{cost_str}:{witness}"
                        entries.append(entry)
                    row.append(", ".join(entries))
                table.append(row)
            max_len = max([len(cell) for row in table for cell in row])
            for row in table:
                for cell in row:
                    print(cell.ljust(max_len + 3), end="")
                print("")


def load_node_counts(csv_path):
    """Load node counts from the given CSV file.
    Args:
        csv_path (str): Path to the CSV file containing node counts.
    Returns:
        inner_counts (list[int]): List of counts for inner nodes with 0 to 256 children.
        leaf_counts (list[int]): List of counts for leaf nodes with 0 to 256 children.
    """

    df = pd.read_csv(csv_path)
    inner_counts = [0] * 257
    leaf_counts = [0] * 257
    for _, row in df[df["Node Kind"] == "Inner"].iterrows():
        size = int(row["Node Size"])
        count = int(row["Count"])
        inner_counts[size] = count
    for _, row in df[df["Node Kind"] == "Leaf"].iterrows():
        size = int(row["Node Size"])
        count = int(row["Count"])
        leaf_counts[size] = count
    return inner_counts, leaf_counts


def load_data():
    """Load node counts and sizes, either from the CSV or from hardcoded values in debug mode.
    Returns:
        inner_counts (list[int]): List of counts for inner nodes with 0 to 256 children.
        inner_node_sizes (list[int]): List of sizes for inner nodes with 0 to 256 children.
        leaf_counts (list[int]): List of counts for leaf nodes with 0 to 256 children.
        leaf_node_sizes (list[int]): List of sizes for leaf nodes with 0 to 256 children.
    """

    if DEBUG:
        inner_node_sizes = [10, 20, 30, 40, 50]
        inner_counts = [1, 1, 5, 2, 8]
        leaf_node_sizes = [10, 20, 30, 40, 50]
        leaf_counts = [1, 1, 5, 2, 8]
    else:
        if len(sys.argv) > 1:
            path = sys.argv[1]
        else:
            path = CSV_PATH

        inner_counts, leaf_counts = load_node_counts(path)

        # cap node sizes at the full node size
        leaf_node_sizes = [min(s, FULL_LEAF_NODE_SIZE) for s in get_leaf_node_sizes()]
        inner_node_sizes = [
            min(s, FULL_INNER_NODE_SIZE) for s in get_inner_node_sizes()
        ]

    return inner_counts, inner_node_sizes, leaf_counts, leaf_node_sizes


inner_counts, inner_node_sizes, leaf_counts, leaf_node_sizes = load_data()
print_best_specializations("Inner", inner_counts, inner_node_sizes)
print_best_specializations("Leaf", leaf_counts, leaf_node_sizes)
