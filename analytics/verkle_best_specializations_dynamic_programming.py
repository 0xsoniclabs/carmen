import sys

import pandas as pd

MAX_SPECIALIZATIONS = 5

DEBUG = False
PRINT_TABLE = False

# The default CSV to load. This can be overridden by a command-line argument.
# Data is generated by ../rust/src/bin/node_stats.rs
CSV_PATH = "../rust/carmen_stats_node_counts_by_kind.csv"

# NOTE: These sizes are based on the current implementation of the trie nodes in Carmen and needs to be manually updated if the implementation changes.

# --- Node size constants ---
# The size of the commitment stored in both inner and leaf nodes
COMMITMENT_SIZE = 32

# --- Inner node constants ---
# The size of a node id stored in inner nodes
ID_SIZE = 6
# The size of the index for a node id stored in sparse inner nodes
ID_INDEX_SIZE = 1
# The number of children of a full inner node
INNER_NODE_CHILDREN = 256
# The size of a full inner node
FULL_INNER_NODE_SIZE = COMMITMENT_SIZE + INNER_NODE_CHILDREN * ID_SIZE

# --- Leaf node constants ---
# The size of a value stored in leaf nodes
VALUE_SIZE = 32
# The size of the index for a value stored in sparse leaf nodes
VALUE_INDEX_SIZE = 1
# The size of the stem in leaf nodes
STEM_SIZE = 31
# The number of children of a full leaf node
LEAF_NODE_CHILDREN = 256
# The number of used bits in a leaf node
USED_BITS = 256 / 8
# The size of a full leaf node
FULL_LEAF_NODE_SIZE = (
    COMMITMENT_SIZE + LEAF_NODE_CHILDREN * VALUE_SIZE + STEM_SIZE + USED_BITS
)

INT_MAX = sys.maxsize


def sparse_leaf_node_size(num_children: int) -> int:
    """Return the size of a sparse leaf node with the given number of children."""
    return (
        COMMITMENT_SIZE
        + num_children * (VALUE_SIZE + VALUE_INDEX_SIZE)
        + STEM_SIZE
        + USED_BITS
    )


def get_leaf_node_sizes() -> list[int]:
    """Return a list of leaf node sizes for all possible numbers of children."""
    leaf_node_sizes = [sparse_leaf_node_size(n) for n in range(256)]
    leaf_node_sizes.append(FULL_LEAF_NODE_SIZE)
    return leaf_node_sizes


def sparse_inner_node_size(num_children: int) -> int:
    """Return the size of a sparse inner node with the given number of children."""
    return COMMITMENT_SIZE + num_children * (ID_SIZE + ID_INDEX_SIZE)


def get_inner_node_sizes() -> list[int]:
    """Return a list of inner node sizes for all possible numbers of children."""
    inner_node_sizes = [sparse_inner_node_size(n) for n in range(INNER_NODE_CHILDREN)]
    inner_node_sizes.append(FULL_INNER_NODE_SIZE)
    return inner_node_sizes


def find_best_specializations(counts, sizes, num_specializations):
    """Find the best specializations for a given list of node counts and sizes, using dynamic programming.
    Args:
        counts (list[int]): List of counts for nodes with 0 to 256 children.
        sizes (list[int]): List of sizes of nodes with 0 to 256 children.
        specializations (int): Number of specializations to consider.
    Returns:
        best_specializations (list[int]): List of the number of children for the best specializations.
        min_cost (int): The minimum storage cost achieved with the best specializations.
        cost_table (list): The dynamic programming table of costs for each range and number of specializations.
    """

    # cost_table[start][end][num_specializations](cost, levels_used)
    cost_table = [
        [
            [(INT_MAX, []) for _ in range(num_specializations)]
            for _ in range(len(counts))
        ]
        for _ in range(len(counts))
    ]
    for end in range(len(counts)):
        for start in range(end + 1):
            if start == 0:
                cost = sizes[end] * sum(counts[start : end + 1])
                cost_table[start][end][0] = (cost, [end])
            else:
                for level in range(start):
                    for num_spec in range(num_specializations - 1):
                        level_cost, levels_used = cost_table[level][start - 1][num_spec]
                        if level_cost == INT_MAX:
                            continue
                        cost = level_cost + sizes[end] * sum(counts[start : end + 1])
                        if cost < cost_table[start][end][num_spec + 1][0]:
                            cost_table[start][end][num_spec + 1] = (
                                cost,
                                levels_used + [end],
                            )

    min_cost, best_specializations = min(
        (
            cost_table[start][len(counts) - 1][num_spec]
            for start in range(len(counts))
            for num_spec in range(num_specializations)
        ),
        key=lambda x: x[0],
        default=(INT_MAX, []),
    )
    return best_specializations, min_cost, cost_table


def print_best_specializations(node_name, counts, sizes):
    """Print the best specializations for a given node type, counts, and sizes."""

    print(f"--- Node type: {node_name} ---")
    for num_specializations in range(1, MAX_SPECIALIZATIONS + 1):
        best_specializations, min_cost, cost_table = find_best_specializations(
            counts, sizes, num_specializations
        )

        print(f"Num Specializations: {num_specializations}")
        print(f"Min cost: {min_cost}")
        print(f"Specializations: {best_specializations}\n")
        if PRINT_TABLE:
            max_len = max(
                [
                    len(str(entry).replace(str(INT_MAX), "INF"))
                    for row in cost_table
                    for entry in row
                ]
            )
            for start, row in enumerate(cost_table):
                for end, col in enumerate(row):
                    if start > end:
                        entry = ""
                    else:
                        entry = str(col).replace(str(INT_MAX), "INF")
                    print(entry.ljust(max_len + 1), end="")
                print("")


def load_node_counts(csv_path):
    """Load node counts from the given CSV file.
    Args:
        csv_path (str): Path to the CSV file containing node counts.
    Returns:
        inner_counts (list[int]): List of counts for inner nodes with 0 to 256 children.
        leaf_counts (list[int]): List of counts for leaf nodes with 0 to 256 children.
    """

    df = pd.read_csv(csv_path)
    inner_counts = [0] + list(df[df["Node Kind"] == "Inner"]["Count"])
    leaf_counts = list(df[df["Node Kind"] == "Leaf"]["Count"])
    assert len(inner_counts) == 257
    assert len(leaf_counts) == 257
    return inner_counts, leaf_counts


def load_data():
    """Load node counts and sizes, either from the CSV or from hardcoded values in debug mode.
    Returns:
        inner_counts (list[int]): List of counts for inner nodes with 0 to 256 children.
        inner_node_sizes (list[int]): List of sizes for inner nodes with 0 to 256 children.
        leaf_counts (list[int]): List of counts for leaf nodes with 0 to 256 children.
        leaf_node_sizes (list[int]): List of sizes for leaf nodes with 0 to 256 children.
    """

    if DEBUG:
        inner_node_sizes = [10, 20, 30, 40, 50]
        inner_counts = [1, 1, 5, 2, 8]
        leaf_node_sizes = [10, 20, 30, 40, 50]
        leaf_counts = [1, 1, 5, 2, 8]
    else:
        if len(sys.argv) > 1:
            path = sys.argv[1]
        else:
            path = CSV_PATH

        inner_counts, leaf_counts = load_node_counts(path)

        # cap node sizes at the full node size
        leaf_node_sizes = [min(s, FULL_LEAF_NODE_SIZE) for s in get_leaf_node_sizes()]
        inner_node_sizes = [
            min(s, FULL_INNER_NODE_SIZE) for s in get_inner_node_sizes()
        ]

    return inner_counts, inner_node_sizes, leaf_counts, leaf_node_sizes


inner_counts, inner_node_sizes, leaf_counts, leaf_node_sizes = load_data()
print_best_specializations("Inner", inner_counts, inner_node_sizes)
print_best_specializations("Leaf", leaf_counts, leaf_node_sizes)
