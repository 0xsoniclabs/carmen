{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccb6ff31",
   "metadata": {},
   "source": [
    "# Read the CSV and get data out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9696bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./carmen_stats_node_distribution.csv')\n",
    "# Remove all empty nodes\n",
    "df = df[df['Node Type'] != 'Empty']\n",
    "# Remove the duplicated entry where `Node Type` == `Node Subtype`\n",
    "df = df[df['Node Type'] != df['Node Subtype']]\n",
    "# Group by `Node Type` and calculate the prefix sum of `Node Count` within each group\n",
    "grouped_df = df.groupby('Node Type').apply(lambda x: x.assign(PrefixSum=x['Node Count'].cumsum())).reset_index(drop=True)\n",
    "# Collect the node info into a nested dictionary\n",
    "node_info = dict()\n",
    "for name, group in grouped_df.groupby('Node Type'):\n",
    "    node_info[name] = dict()\n",
    "    node_info[name]['total_count'] = group['Node Count'].sum()\n",
    "    node_info[name]['subtype_count'] = dict()\n",
    "    node_info[name]['prefix_sum'] = dict()\n",
    "    for index, row in group.iterrows():\n",
    "        id = int(row['Node Subtype'].strip(name + '_')) - 1\n",
    "        node_info[name]['subtype_count'][id] = row['Node Count']\n",
    "        node_info[name]['prefix_sum'][id] = row['PrefixSum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45cfb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sizes of the nodes\n",
    "\n",
    "commitment_size = 32\n",
    "id_size = 6\n",
    "id_index = 1\n",
    "full_inner_node_size = commitment_size + 256 * id_size\n",
    "sparse_inner_node_size = lambda num_children: commitment_size + num_children * (id_size + id_index)\n",
    "inner_node_sizes = [sparse_inner_node_size(element + 1) for element in range(255)]\n",
    "inner_node_sizes.append(full_inner_node_size)\n",
    "\n",
    "value_size = 32\n",
    "value_index = 1\n",
    "full_leaf_node_size = commitment_size + 256 * value_size\n",
    "sparse_leaf_node_size = lambda num_children: commitment_size + num_children * (value_size + value_index)\n",
    "leaf_node_sizes = [sparse_leaf_node_size(element + 1) for element in range(255)]\n",
    "leaf_node_sizes.append(full_leaf_node_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcaf084",
   "metadata": {},
   "source": [
    "# Brute force approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ef3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from sortedcontainers import SortedSet, SortedDict\n",
    "import itertools\n",
    "\n",
    "def calculate_size(num_nodes_to_use, prefix_sum: dict, max_node: int, node_sizes: dict):\n",
    "    assert num_nodes_to_use > 0\n",
    "\n",
    "    # All combination of num-nodes - 1 indexes, with the biggest node always included\n",
    "    available_nodes = [i for i in prefix_sum.keys() if i != max_node]\n",
    "    initial_indexes = SortedSet() # The set of indexes of the selected node sizes\n",
    "    initial_indexes.add(max_node) # always include the biggest node\n",
    "\n",
    "    def calculate_size_for_indexes(index_combination):\n",
    "        cur_indexes = initial_indexes.copy()\n",
    "        cur_indexes.update(index_combination)\n",
    "        space_occupied = 0\n",
    "        already_covered_nodes = 0\n",
    "        cur_solution = SortedDict()\n",
    "        for value in cur_indexes:\n",
    "            num_nodes_covered = prefix_sum[value] - already_covered_nodes\n",
    "            space_occupied += node_sizes[value] * num_nodes_covered\n",
    "            already_covered_nodes += num_nodes_covered\n",
    "            cur_solution[value] = num_nodes_covered\n",
    "        return cur_solution, space_occupied\n",
    "    \n",
    "    # Initial minimum solution to the worst case (only the biggest node)\n",
    "    min_space_occupied = prefix_sum[max_node] * node_sizes[max_node]\n",
    "    min_solution = SortedDict()\n",
    "    min_solution[max_node] = prefix_sum[max_node]\n",
    "\n",
    "    index_combinations = list(itertools.combinations(available_nodes, num_nodes_to_use - 1))\n",
    "    max_concurrent = 100\n",
    "    prev = 0 \n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        while prev < len(index_combinations):\n",
    "            futures = []\n",
    "            for i in range(prev, min(prev + max_concurrent, len(index_combinations))):\n",
    "                futures.append(executor.submit(calculate_size_for_indexes, index_combinations[i]))\n",
    "            for future in as_completed(futures):\n",
    "                cur_solution, space_occupied = future.result()\n",
    "                if space_occupied < min_space_occupied:\n",
    "                    min_space_occupied = space_occupied\n",
    "                    min_solution = cur_solution.copy()\n",
    "            prev += max_concurrent\n",
    "    return min_solution, min_space_occupied\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78308a5d",
   "metadata": {},
   "source": [
    "# Greedy approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af451ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sortedcontainers import SortedSet, SortedDict\n",
    "import sys\n",
    "\n",
    "def solve_greedy(num_nodes_to_use, node_prefix_sum: dict, max_node: int, node_sizes: dict):\n",
    "    assert num_nodes_to_use > 0\n",
    "\n",
    "    # All combination of num-nodes - 1 indexes, with the biggest node always included\n",
    "    available_nodes = [i for i in node_prefix_sum.keys() if i != max_node]\n",
    "    initial_indexes = SortedSet() # The set of indexes of the selected node sizes\n",
    "    initial_indexes.add(max_node) # always include the biggest node\n",
    "\n",
    "    def calculate_size_for_indexes(indices):\n",
    "        space_occupied = 0\n",
    "        already_covered_nodes = 0\n",
    "        cur_solution = SortedDict()\n",
    "        for value in indices:\n",
    "            num_nodes_covered = node_prefix_sum[value] - already_covered_nodes\n",
    "            space_occupied += node_sizes[value] * num_nodes_covered\n",
    "            already_covered_nodes += num_nodes_covered\n",
    "            cur_solution[value] = num_nodes_covered\n",
    "        return cur_solution, space_occupied\n",
    "    \n",
    "    # Initial minimum solution to the worst case (only the biggest node)\n",
    "    min_size = node_prefix_sum[max_node] * node_sizes[max_node]\n",
    "    min_solution = SortedDict()\n",
    "    min_solution[max_node] = node_prefix_sum[max_node]\n",
    "\n",
    "    while len(min_solution) < num_nodes_to_use:\n",
    "        min_tmp_solution = min_solution.copy()\n",
    "        min_tmp_size = sys.maxsize\n",
    "        for candidate_key in available_nodes:\n",
    "            if candidate_key in min_solution:\n",
    "                continue\n",
    "            current_indexes = SortedSet(min_solution.keys())\n",
    "            current_indexes.add(candidate_key)\n",
    "            current_solution, current_size = calculate_size_for_indexes(current_indexes)\n",
    "            if current_size < min_tmp_size:\n",
    "                min_tmp_size = current_size\n",
    "                min_tmp_solution = current_solution\n",
    "        min_solution = min_tmp_solution\n",
    "        min_size = min_tmp_size\n",
    "\n",
    "    solution = dict()\n",
    "    for key in min_solution:\n",
    "        solution[key + 1] = min_solution[key]\n",
    "    return solution, min_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29efd9cb",
   "metadata": {},
   "source": [
    "# Mixed Integer Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851518b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pulp import *\n",
    "\n",
    "def solve_mip(num_nodes_to_use, node_count_by_type: dict, node_prefix_sum: dict, max_node: int, node_sizes: dict, greedy_solution: dict, node_pruning_threshold: float):\n",
    "    greedy_dict, _ = greedy_solution\n",
    "    total_node_count = max(node_prefix_sum.values())\n",
    "    assert num_nodes_to_use > 0\n",
    " \n",
    "    problem = LpProblem(\"Trie size problem\", LpMinimize)\n",
    "    nodes_range = [i for i in node_prefix_sum.keys()]\n",
    "    # Upper bound is the prefix sum of each node type\n",
    "    nodes_lp_variable = {\n",
    "        i: LpVariable(f\"n_{i}\", lowBound=0, upBound=node_prefix_sum[i], cat=LpInteger)\n",
    "        for i in nodes_range\n",
    "    }\n",
    "    # Use the greedy solution as initial solution\n",
    "    for i in greedy_dict.keys():\n",
    "        nodes_lp_variable[i - 1].setInitialValue(greedy_dict[i])\n",
    "    # Setup linked binary variables\n",
    "    node_exist_binary = LpVariable.dicts(\"n_binary\", nodes_range, 0, 1, cat = 'Binary')\n",
    "    # Objective function\n",
    "    problem += lpSum([nodes_lp_variable[i] * node_sizes[i] for i in nodes_range]), \"Minimize trie size\"\n",
    "    # Constraints\n",
    "    # ## Sum of number of inner nodes must be equals to the total number of inner nodes\n",
    "    problem += lpSum(nodes_lp_variable[i] for i in nodes_range) == total_node_count, \"Must cover all nodes\"\n",
    "    # ## Exclude all variable with less than threshold% of the total number of nodes\n",
    "    threshold_count = (node_pruning_threshold * total_node_count) / 100.0\n",
    "    print(\"Pruning threshold count: \", threshold_count)\n",
    "    for i in nodes_range:\n",
    "        var_size = node_count_by_type[i]\n",
    "        if var_size < threshold_count:\n",
    "            problem += nodes_lp_variable[i] == 0\n",
    "    # ## Must cover all nodes minus the one covered by previous nodes\n",
    "    for i in nodes_range:\n",
    "        problem += nodes_lp_variable[i] <= node_prefix_sum[i] - lpSum(nodes_lp_variable[j] for j in range(0, i) if j in nodes_range), f\"node {i} cover at at least its node minus the one covered by the previous nodes\"\n",
    "    # ## Special case: biggest variable must cover the remaining nodes\n",
    "    last_node_index = max(node_count_by_type.keys())\n",
    "    problem += node_count_by_type[last_node_index] <= nodes_lp_variable[max_node], \"Last node must cover remaining nodes\"\n",
    "    # ## Link the variables to the binary ones\n",
    "    for i in nodes_range:\n",
    "        problem += nodes_lp_variable[i] <= (node_prefix_sum[i] + 1) * node_exist_binary[i], f\"Link variable {i} existence to usage\"\n",
    "    # ## Limit number of variables to use\n",
    "    problem += lpSum([node_exist_binary[i] for i in nodes_range]) == num_nodes_to_use, \"Limit number of variables to use\"\n",
    "    \n",
    "    # Solve the problem\n",
    "    solver = getSolver(\"SCIP_PY\", msg=0, threads=os.cpu_count())\n",
    "    problem.solve(solver)\n",
    "    \n",
    "    solution = dict()\n",
    "    for j in nodes_range:\n",
    "        if nodes_lp_variable[j].varValue>= 1:\n",
    "            solution[j + 1] = nodes_lp_variable[j].varValue # every node is shifted by 1\n",
    "    size = problem.objective.value()\n",
    "\n",
    "    return solution, size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64522ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(solution_type, solution, size, prev_solution_size, writer):\n",
    "    writer.write(f\"{solution_type} solution:\\n\")\n",
    "    writer.write(f\"    {len(solution)}: \")\n",
    "    writer.write(f\"{solution}\\n\")\n",
    "    writer.write(f\"       Size in MiB: {size / (1024 * 1024)}\\n\")\n",
    "    if prev_solution_size != None:\n",
    "        writer.write(f\"       Saved space in MiB: {(prev_solution_size - size) / (1024 * 1024)}\\n\")\n",
    "        writer.write(f\"       Saved space in percentage: {100.0 * (prev_solution_size - size) / prev_solution_size}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50513110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_solution_sizes(node_name, node_range, solution_sizes_greedy, solution_sizes_mip):\n",
    "        def _plot(node_name, node_range, solution_sizes_greedy, solution_sizes_mip):\n",
    "                sns.set_theme()\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.plot(node_range, [size / (1024 * 1024) for size in solution_sizes_greedy], marker='o', label='Greedy Solution Size (MiB)')\n",
    "                plt.plot(node_range, [size / (1024 * 1024) for size in solution_sizes_mip], marker='o', label='MIP Solution Size (MiB)')\n",
    "                plt.title(f'Solution Sizes for {node_name} Nodes')\n",
    "                plt.xlabel('Number of Node Types Used')\n",
    "                plt.ylabel('Solution Size (MiB)')\n",
    "                plt.xticks(node_range)\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "                plt.show()\n",
    "\n",
    "        _plot(node_name, node_range, solution_sizes_greedy, solution_sizes_mip)\n",
    "        # plot starting from position 1\n",
    "        solution_sizes_greedy = solution_sizes_greedy[1:]\n",
    "        solution_sizes_mip = solution_sizes_mip[1:]\n",
    "        node_range = node_range[1:]\n",
    "        _plot(node_name + \" (without size 1)\", node_range, solution_sizes_greedy, solution_sizes_mip)\n",
    "\n",
    "def solve(node_name, node_range, node_info: dict, max_node: int, node_sizes: dict, node_pruning_threshold: float, writer):\n",
    "        solution_sizes_greedy = []\n",
    "        solution_sizes_mip = []\n",
    "        # add max_node to the node_info if not present\n",
    "        if max_node not in node_info['subtype_count']:\n",
    "                node_info['subtype_count'][max_node] = 0\n",
    "        if max_node not in node_info['prefix_sum']:\n",
    "                node_info['prefix_sum'][max_node] = node_info['prefix_sum'][max(node_info['prefix_sum'].values())]\n",
    "\n",
    "        writer.write(\"\\n-------------------------------\\n\")\n",
    "        writer.write(f\"--------- {node_name} nodes ---------\\n\")\n",
    "        prev_greedy_solution_size = None\n",
    "        prev_ilp_solution_size = None\n",
    "        for i in node_range:\n",
    "                greedy_solution = solve_greedy(i, node_info['prefix_sum'], max_node, node_sizes)\n",
    "                print_results(\"Greedy\", greedy_solution[0], greedy_solution[1], prev_greedy_solution_size, writer)\n",
    "                solution_sizes_greedy.append(greedy_solution[1])\n",
    "                ilp_solution, ilp_size = solve_mip(i, node_info['subtype_count'], node_info['prefix_sum'], 255, node_sizes, greedy_solution, node_pruning_threshold)\n",
    "                print_results(\"MIP\", ilp_solution, ilp_size, prev_ilp_solution_size, writer)\n",
    "                solution_sizes_mip.append(ilp_size)\n",
    "                writer.write(f\"Difference between Greedy and MIP: {(greedy_solution[1] - ilp_size) / (ilp_size) * 100}%\\n\")\n",
    "                prev_greedy_solution_size = greedy_solution[1]\n",
    "                prev_ilp_solution_size = ilp_size\n",
    "        plot_solution_sizes(node_name, node_range, solution_sizes_greedy, solution_sizes_mip)\n",
    "        writer.write(\"-------------------------------\\n\\n\")\n",
    "\n",
    "with open(\"node_optimization_results.txt\", \"w\") as writer:\n",
    "        solve(\"Inner\", range(1,5), node_info['Inner'], 255, inner_node_sizes, 0, writer)\n",
    "        solve(\"Leaf\", range(1,5), node_info['Leaf'], 255, leaf_node_sizes, 0.004, writer)\n",
    "        writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5707408a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
